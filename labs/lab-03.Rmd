---
title: "Lab 03 Preparing Data for Visualization"
subtitle: "RE 519 Data Analytics and Visualization | Autumn 2025"
author: "" #remember to add to your name when you submit the lab
date: ""
output:
  cleanrmd::html_document_clean:
    theme: almond
    toc: true 
    toc_depth: 3
    css: custom.css
    mathjax: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    md_extensions: +tex_math_dollars+tex_math_single_backslash   
    df_print: paged    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

<!-- start of the main lab content --> 

In lab 3, we are going to explore tidy data, start to visualize data using R, and look at GitHub. The primary dataset we are using is [Zillow Home Value Index (ZHVI)](https://www.zillow.com/research/data/), a measure of the typical home value and market changes across a given region and housing type. More information about what ZHVI is and how itâ€™s calculated is available on [this overview page](https://www.zillow.com/research/methodology-neural-zhvi-32128/). 

The due day for each lab can be found on the [course wesbite](https://www.yuehaoyu.com/data-analytics-visualization/). The submission should include Rmd, html, and any other files required to rerun the codes. **For Lab 1â€“3, the use of any generative AI tool (ChatGPT, Copilot, etc.) is prohibited**. We will run AI detection on each submission. More information about [Academic Integrity](https://www.yuehaoyu.com/data-analytics-visualization/syllabus/#academic-integrity) and [the Use of AI](https://www.yuehaoyu.com/data-analytics-visualization/syllabus/#use-of-ai).

> **Recommended Reading** <br>
> [Chapter 2, 6, Modern Data Science with R. Baumer et al. 2024.](https://mdsr-book.github.io/mdsr3e) <br>
> [Tidy Data, *The Journal of Statistical Software*, Hadley Wickham, 2014.](https://vita.had.co.nz/papers/tidy-data.html)

---

## Lab 03-A: Tidy Data and GitHub

```{r message=FALSE}
library('tidyverse')
library('ggplot2') # the major package for visualization in R
```

### Data Preparation 

Instead of using API or R data package as we did in Lab 1 and 2, we will use data on our local device. We have organized the [Zillow Home Value Index (ZHVI)](https://www.zillow.com/research/data/) for the largest 30 [Metropolitan Statistical Ares (MSA)](https://en.wikipedia.org/wiki/Metropolitan_statistical_area) and their 2024 population in csv file `zillow_hvi_msa.csv`. [Comma-separated values (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) is a text data format that uses commas to separate delimiter-separated values, and newlines to separate records.

```{r}
hvi <- read_csv("zillow_hvi_msa.csv")
```

`CSV` files are just plain text. They do not store metadata such as column types, units, or formats. So. when we use `read_csv()`, it automatically guesses column types by inspecting the data. Sometimes its guess is wrong, we need to specify the types using `spec()`.

```{r}
hvi <- read_csv("zillow_hvi_msa.csv",
  col_types = cols(
    RegionName = col_character(),
    StateName  = col_character(),
    RegionID   = col_double(),
    Popu2024   = col_number(),
    .default   = col_double()   # for other columns
  )
)
head(hvi, 3)
```

We will not see the message if we specified the data types. let's have a look of the first 3 rows of this data. The data is ZHVI All Home (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted from Zillow Research. The data includes ZHVI for 30 MSA from 2000 to 2025 by month!

Currently, the `hvi` dataset has 30 rows and 312 columns. This presentation of the data has some advantages: we can easily look through the index for single city by date (one row). But, we have 308 columns for house value index, which treated as separate variables now. In data science, researchers defined a particular format of data table: **tidy data** - [A research paper about tidy data](https://www.jstatsoft.org/article/view/v059i10).

### Data Tidying

**This section was adopted from [Tidy data page](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html), authored by [Hadley Wickham](https://hadley.nz), I believe.**

> Happy families are all alike; every unhappy family is unhappy in its own way â€” Leo Tolstoy

Like families, tidy datasets are all alike but every messy dataset is messy in its own way. The principles of tidy data provide a standard way to organize data values within a dataset. A standard makes initial data cleaning easier because you donâ€™t need to start from scratch and reinvent the wheel every time. The tidy data standard has been designed to facilitate initial exploration and analysis of the data, and to simplify the development of data analysis tools that work well together. 

#### Data Semantics

A dataset is a collection of **values**, usually either numbers or strings. Values are organised in two ways: every value belongs to a variable and an observation. 

- A **variable** contains all values that measure the same underlying attribute (like height, temperature, duration) across units. 
- An **observation** contains all values measured on the same unit (like a person, or a day, or a race) across attributes.

```{r}
head(hvi, 3)
```

Look at our `hvi` dataset, it contains 9,360 values representing **312** variables and **30** observations. The variables are:

- `RegionID`: a unique regional ID defined by Zillow
- `RegionalName`: the name of 30 MSA
- `Popu2024`: the population of MSA in 2024 based on US Census Bureau
- `StateName`: state name
- 308 columns representing dates: Housing Value Index on that date

A tidy version of the data looks like this: 

```{r}
hvi_tidy <- hvi %>%
  pivot_longer( # using `pivot_longer` to reshape wide â†’ long
    cols = -c("RegionID", "RegionName", "Popu2024", "StateName"), # keep these 4 as identifier variables (donâ€™t pivot them)
    names_to = "Date",  # old column names (like "1/31/00") become a new column called Date                 
    values_to = "HVI" # the cell values go into a new column called HVI 
    # values_drop_na = TRUE; default as FALSE; if TRUE, will remove rows with missing HVI.
  ) %>%
  mutate(
    Date = as.Date(Date, format = "%m/%d/%y")                   
  )
head(hvi_tidy,3)
```

Look at our `hvi_tidy` dataset again, it contains 9,360 values representing **6** variables and **9,240** observations. The variables are:

- `RegionID`: a unique regional ID defined by Zillow
- `RegionalName`: the name of 30 MSA
- `Popu2024`: the population of MSA in 2024 based on US Census Bureau
- `StateName`: state name
- `Date`: **NEW** - observation date
- `HVI`: **NEW** - Housing Value Index from Zillow

The tidy data frame explicitly tells us the definition of an observation. Every combination of `RegionName` and `Date` is a single measured observation (`HVI`). It's important to clearly define **what is an observation**. In the case of HVI, we are interested in HVI for sure! For an observation, such as `220834.8`, we need know two information: region and date.

#### Tidy data

In tidy data:

- Each variable is a column; each column is a variable.
- Each observation is a row; each row is an observation.
- Each value is a cell; each cell is a single value.

Tidy data makes it easy for an analyst or a computer to extract needed variables because it provides a standard way of structuring a dataset. Tidy data is particularly well suited for vectorised programming languages like R, because the layout ensures that values of different variables from the same observation are always paired. Many R packages, such as `ggplot2` are designed around the tidy data principles.

### Missing Values

In `pivot_longer`, there is an optional argument called `values_drop_na =`, default as `FALSE`. If setting as `TRUE`, it will remove rows with missing HVI. We set as `FALSE` but is there any `NA` (Not Available) values? 

We can use `is.na()` to check and there are 3 missing value in  `HVI` column:

```{r}
colSums(is.na(hvi_tidy))
```

We can remove NA or smooth/impute them based on their neighbors. We will just remove them here. But, there are many ways you can do data interpolation. It can based on known temporal neighbors, spatial neighbors, group-based neighbors. It goes beyond this course but it's an important problem for data science. If you are interested in missing data, you can refer to this book: [Statistical Analysis with Missing Data](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119482260).

```{r}
# remove NA then we can see there are 9237 rows afterwards, 3 missing values are removed
hvi_tidy_NA_remove <- hvi_tidy %>% 
  filter(!is.na(HVI))
dim(hvi_tidy_NA_remove)
```



### ðŸ“š TODO: Critique of Data Visualizations

**5 points**

As we learn more about data visualization, we have begun to discuss some general principles. For this section, please find an example of a visualization or infographic that impresses you- either in a good or bad way. Please attach the example image, give the link/source, and:

1. describe what the visualization is trying to communicate
2. discuss what it does and does not do well using the principles we talked about in class
3. comment on two visualizations posted by classmates (optional)

A few probing questions to think about:

- Is the data visualization static, motion or interactive?
- Is it narrative or exploratory?
- What kind of purpose do you think it serves? How would you order its objectives (appeal, comprehension and retention)?
- Does it contain the basic elements of a graph (e.g. title, axis label, encoding)? Is anything missing or not clear to audience?
- What kind of encoding does it use (e.g. position, length, slope, angle, area, color hue, etc)? How effective in terms of precision of such encoding elements? 
- What kind of organization principles do you observe (e.g.hierarchy, unity, balance, grouping and spacing)? Is principle lacking in the graph?
- Do you think your psychological needs have all been met by this source (e.g. autonomy, relatedness and competence)?

---

## Lab 03-B: Basic Exploratory Data Analysis in R

Starting from this lab session, we are going to conduct data visualization using R and [ggplot2](https://ggplot2.tidyverse.org). You don't have to install `ggplot2` separately because it is already a part of `tidyverse`. 

Exploratory Data Analysis (EDA) is the process of summarizing, visualizing, and checking data to uncover patterns, detect outliers, and identify unexpected features. It helps you understand the structure and quality of your dataset before applying formal statistical models or machine learning methods. The key of EDA is **not** aesthetics, design, or storytelling, but rather developing an understanding of the data itself. However, for learning purposes, we will use ggplot2 because it provides a consistent and flexible framework for visualizing data in R. In realty, you can use any tool, base R plotting, Tableau, Excel, for EDA. What matters is the insight you gain, not the tool itself.

### Skim Datasets

The first step of Exploratory Data Analysis (EDA) is to quickly check the structure of the dataset: variable types, missing values, and basic distributions. The `skimr` package provides the `skim()` function, which offers a richer summary than `summary()` we used before.

```{r}
# install.packages("skimr") # you only need to install once
library(skimr)
skim(hvi_tidy) # run `skim()` to get a quick overview of the dataset
```

Note: `complete_rate` is the proportion of non-missing values in that variable. In the HTML, we find it is 1 for `HVI` but it's not the case. This happens because the value is very close to 1 (e.g., 0.9996) and is rounded up.

### Core Logic of `ggplot2`


### Distribution of Univariate Variable

#### Histograms

#### Boxplots

#### Bar Chart 

### Relationship Between Multivariate Variables

#### Scatter Plot

```{r}
ggplot(
  data = hvi_tidy_NA_remove %>%
    filter(Date == as.Date("2025-08-31")),
  aes(x = Popu2024, y = HVI)
) +
  geom_point() +
  geom_smooth(
    method = "lm",
    formula = y ~ x,
    se = TRUE,
    color = "red"
  ) +
  theme_minimal()
```


#### Bubble Chart

#### Heatmap

#### Run Chart



We did not touch on any geospatial data even it is an important part of real estate or urban study. We will talk about how to produce maps in R later this quarter.    

### ðŸ“š TODO: 



Using the National Mortgage Database data create a very pretty table of descriptive statistics using any table package. I suggest either looking at the **Outstanding Residential Mortgage Statistics** for **States** or **Residential Mortgage Performance Statistics** for **States.**

[https://www.fhfa.gov/data/national-mortgage-database-aggregate-statisticsLinks to an external site.](https://www.fhfa.gov/data/national-mortgage-database-aggregate-statistics)

In your table, show basic summary statistics such as mean, median, min/max, 25th/75th percentiles, for both Washington and the rest of the US. 

Additionally, create 3-4 ggplots that would make sense to view side by side in a grid and try to make the plots in the grid connect together (ex. similar legend, color scheme, title) as well as tell an interesting story. You may want to connect state-level statistics from ACS with the NMDB data (make sure you are comparing data from the same year). 

Be sure to review the technical documentation to understand what the statistics represent. You will likely need to filter or pivot_wider() the data since it is in a long format. 

Add one paragraph explaining your table and charts.

\-----

Helpful resources:

[https://rfortherestofus.com/2019/11/how-to-make-beautiful-tables-in-rLinks to an external site.](https://rfortherestofus.com/2019/11/how-to-make-beautiful-tables-in-r)

[https://epirhandbook.com/new_pages/tables_descriptive.htmlLinks to an external site.](https://epirhandbook.com/new_pages/tables_descriptive.html)

[https://r-graph-gallery.com/table.htmlLinks to an external site.](https://r-graph-gallery.com/table.html)

Multiple plots next to each other:

[https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.htmlLinks to an external site.](https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html)

[https://rfortherestofus.com/2021/11/multicolumnLinks to an external site.](https://rfortherestofus.com/2021/11/multicolumn)

Facets (Creating multiple plots split by one categorical variable):

[https://bookdown.org/yih_huynh/Guide-to-R-Book/facet-wrapping.htmlLinks to an external site.](https://bookdown.org/yih_huynh/Guide-to-R-Book/facet-wrapping.html)




## Acknowledgement

The materials are developed by [Haoyu Yue](www.yuehaoyu.com) based materials from [Dr. Feiyang Sun at UC San Diego](https://fsun.ucsd.edu), Siman Ning and Christian Phillips at University of Washington, [Dr. Charles Lanfear at University of Cambridge](https://clanfear.github.io).
