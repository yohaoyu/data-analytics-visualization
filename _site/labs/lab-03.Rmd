```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

<!-- start of the main lab content --> 

In lab 3, we are going to explore tidy data, start to visualize data using R, and look at GitHub. The primary dataset we are using is [Zillow Home Value Index (ZHVI)](https://www.zillow.com/research/data/), a measure of the typical home value and market changes across a given region and housing type. More information about what ZHVI is and how it’s calculated is available on [this overview page](https://www.zillow.com/research/methodology-neural-zhvi-32128/). 

The due day for each lab can be found on the [course wesbite](https://www.yuehaoyu.com/data-analytics-visualization/). The submission should include Rmd, html, and any other files required to rerun the codes. **For Lab 1–3, the use of any generative AI tool (ChatGPT, Copilot, etc.) is prohibited**. We will run AI detection on each submission. More information about [Academic Integrity](https://www.yuehaoyu.com/data-analytics-visualization/syllabus/#academic-integrity) and [the Use of AI](https://www.yuehaoyu.com/data-analytics-visualization/syllabus/#use-of-ai).

> Recommended Reading: [Chapter 2, 3, 6, Modern Data Science with R, 3rd edition. Baumer et al. 2024.](https://mdsr-book.github.io/mdsr3e)

## Lab 03-A: Tidy Data and GitHub

```{r message=FALSE}
library('tidyverse')
#install.packages('ggplot2') # you only need to run the installation once
library('ggplot2') # the major package for visualization in R
```

### Data Preparation 

Instead of using API or R data package as we did in Lab 1 and 2, we will use data on our local device. We have organized the [Zillow Home Value Index (ZHVI)](https://www.zillow.com/research/data/) for the largest 30 [Metropolitan Statistical Ares (MSA)](https://en.wikipedia.org/wiki/Metropolitan_statistical_area) and their 2024 population in csv file `zillow_hvi_msa.csv`. [Comma-separated values (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) is a text data format that uses commas to separate delimiter-separated values, and newlines to separate records.

```{r}
hvi <- read_csv("zillow_hvi_msa.csv")
```

`CSV` files are just plain text. They do not store metadata such as column types, units, or formats. So. when we use `read_csv()`, it automatically guesses column types by inspecting the data. Sometimes its guess is wrong, we need to specify the types using `spec()`.

```{r}
hvi <- read_csv("zillow_hvi_msa.csv",
  col_types = cols(
    RegionName = col_character(),
    StateName  = col_character(),
    RegionID   = col_double(),
    Popu2024   = col_number(),
    .default   = col_double()   # for other columns
  )
)
head(hvi, 3)
```

We will not see the message if we specified the data types. let's have a look of the first 3 rows of this data. The data is ZHVI All Home (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted from Zillow Research. The data includes ZHVI for 30 MSA from 2000 to 2025 by month!

### Very Simple Git and GitHub

- Every change you make is saved in history, so you can always go back.
- If something breaks, you can roll back to a working version.
- Multiple people can work on the same project without overwriting each other.
- Your code and documents are safe, even if your computer crashes.
- Most of the data science ecosystem (R packages, Python libraries, statistical models, tutorials) lives on GitHub.

There are two main ways to use GitHub:

1. Terminal (Command Line) – more powerful and professional, gives you full control.
2. [GitHub Desktop](https://github.com/apps/desktop) – easier for beginners, has a user-friendly interface.

We will using GitHub Desktop:

1. Download and install [GitHub Desktop](https://github.com/apps/desktop).
2. [Sign up a free GitHub account](https://github.com/signup).
3. Sign in with your GitHub account on GitHub Desktop.
4. Create a [new public repository](https://github.com/new).
5. Click “Clone a repository” to copy from GitHub to your computer.
6. Add this `.Rmd` and `html` to your local repository.
7. Commit changes with a short message (e.g., “Lab 1 for RE 519”).
8. Click “Push origin” to upload your changes back to GitHub.
9. You can check your changes on GitHub now. 

## Lab 03-B: Basic Exploratory Data Analysis in R





### 📚 TODO: Critique of Data Visualizations

**5 points**

As we learn more about data visualization, we have begun to discuss some general principles. For this section, please find an example of a visualization or infographic that impresses you- either in a good or bad way. Please attach the example image, give the link/source, and:

1. describe what the visualization is trying to communicate
2. discuss what it does and does not do well using the principles we talked about in class
3. comment on two visualizations posted by classmates (optional)

A few probing questions to think about:

- Is the data visualization static, motion or interactive?
- Is it narrative or exploratory?
- What kind of purpose do you think it serves? How would you order its objectives (appeal, comprehension and retention)?
- Does it contain the basic elements of a graph (e.g. title, axis label, encoding)? Is anything missing or not clear to audience?
- What kind of encoding does it use (e.g. position, length, slope, angle, area, color hue, etc)? How effective in terms of precision of such encoding elements? 
- What kind of organization principles do you observe (e.g.hierarchy, unity, balance, grouping and spacing)? Is principle lacking in the graph?
- Do you think your psychological needs have all been met by this source (e.g. autonomy, relatedness and competence)?



### 📚 TODO: 






Using the National Mortgage Database data create a very pretty table of descriptive statistics using any table package. I suggest either looking at the **Outstanding Residential Mortgage Statistics** for **States** or **Residential Mortgage Performance Statistics** for **States.**

[https://www.fhfa.gov/data/national-mortgage-database-aggregate-statisticsLinks to an external site.](https://www.fhfa.gov/data/national-mortgage-database-aggregate-statistics)

In your table, show basic summary statistics such as mean, median, min/max, 25th/75th percentiles, for both Washington and the rest of the US. 

Additionally, create 3-4 ggplots that would make sense to view side by side in a grid and try to make the plots in the grid connect together (ex. similar legend, color scheme, title) as well as tell an interesting story. You may want to connect state-level statistics from ACS with the NMDB data (make sure you are comparing data from the same year). 

Be sure to review the technical documentation to understand what the statistics represent. You will likely need to filter or pivot_wider() the data since it is in a long format. 

Add one paragraph explaining your table and charts.

\-----

Helpful resources:

[https://rfortherestofus.com/2019/11/how-to-make-beautiful-tables-in-rLinks to an external site.](https://rfortherestofus.com/2019/11/how-to-make-beautiful-tables-in-r)

[https://epirhandbook.com/new_pages/tables_descriptive.htmlLinks to an external site.](https://epirhandbook.com/new_pages/tables_descriptive.html)

[https://r-graph-gallery.com/table.htmlLinks to an external site.](https://r-graph-gallery.com/table.html)

Multiple plots next to each other:

[https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.htmlLinks to an external site.](https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html)

[https://rfortherestofus.com/2021/11/multicolumnLinks to an external site.](https://rfortherestofus.com/2021/11/multicolumn)

Facets (Creating multiple plots split by one categorical variable):

[https://bookdown.org/yih_huynh/Guide-to-R-Book/facet-wrapping.htmlLinks to an external site.](https://bookdown.org/yih_huynh/Guide-to-R-Book/facet-wrapping.html)


## Acknowledgement

The materials are developed based materials from [Dr. Feiyang Sun at UC San Diego](https://fsun.ucsd.edu), Siman Ning and Christian Phillips at UW, [Dr. Charles Lanfear at University of Cambridge](https://clanfear.github.io).
